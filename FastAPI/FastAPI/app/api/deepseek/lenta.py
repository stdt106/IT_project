import feedparser
import requests
from pathlib import Path
from bs4 import BeautifulSoup
from FastAPI.app.api.deepseek.service import generate_summary
from FastAPI.app.services.logger import setup_logger

logger = setup_logger('lenta_parser')

def fetch_lenta_article_text(url):
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'
    }
    response = requests.get(url, headers=headers)
    if response.status_code != 200:
        return ""
    soup = BeautifulSoup(response.text, "html.parser")
    body = soup.find("div", class_="topic-body__content")
    if not body:
        return ""
    paragraphs = body.find_all("p")
    return "\n\n".join(p.get_text(" ", strip=True) for p in paragraphs)

def run_lenta_parser():
    logger.info("üîç –ó–∞–ø—É—Å–∫ –ø–∞—Ä—Å–µ—Ä–∞ LENTA")
    rss_url = "https://lenta.ru/rss/news"

    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"
    }

    try:
        response = requests.get(rss_url, headers=headers, timeout=10)
        response.raise_for_status()
        feed = feedparser.parse(response.content)
    except requests.RequestException as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ RSS: {e}")
        return

    logger.info(f"üì• RSS –ø–æ–ª—É—á–µ–Ω. –ù–∞–π–¥–µ–Ω–æ {len(feed.entries)} –∑–∞–ø–∏—Å–µ–π.")

    if not feed.entries:
        logger.warning("‚ùó RSS –ø—É—Å—Ç–æ–π ‚Äî –Ω–æ–≤–æ—Å—Ç–µ–π –Ω–µ—Ç.")
        return

    link = feed.entries[0].link
    txt = fetch_lenta_article_text(link)

    if not txt:
        logger.warning("‚ùó –ü—É—Å—Ç–æ–π —Ç–µ–∫—Å—Ç —Å—Ç–∞—Ç—å–∏.")
        return

    base = Path(__file__).parent
    save_path = base / "neww.json"
    sent_path = base / "sent_news.json"

    generate_summary(txt, save_path, sent_path)


if __name__ == "__main__":
    run_lenta_parser()
