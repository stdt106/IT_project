import os
import requests
import json
from dotenv import load_dotenv
from pathlib import Path
from FastAPI.app.services.logger import setup_logger

logger = setup_logger('deepseek_service')

def generate_summary(txt: str, save_path: Path, sent_path: Path):
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Ç–µ–∫—Å—Ç –Ω–æ–≤–æ—Å—Ç–∏ –≤ GPT –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç"""

    load_dotenv(os.path.join(os.path.dirname(__file__), '..', '..', '..', '..', '.env'))
    TSS = os.getenv("TSS")

    if sent_path.exists():
        with open(sent_path, "r", encoding="utf-8") as f:
            last = json.load(f)
        if last.get("full_text", "").strip() == txt.strip():
            logger.info("üü° –≠—Ç–∞ –Ω–æ–≤–æ—Å—Ç—å —É–∂–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–ª–∞—Å—å.")
            return

    url = "https://api.intelligence.io.solutions/api/v1/chat/completions"
    headers = {
        "Content-Type": "application/json",
        "Authorization": TSS,
    }

    data = {
        "model": "deepseek-ai/DeepSeek-R1",
        "messages": [
            {"role": "system",
             "content": "You are a helpful assistant."
             },
            {"role": "user",
             "content": f"–¢–µ–±–µ –Ω–∞ –≤—Ö–æ–¥ –ø–æ–¥–∞—ë—Ç—Å—è –Ω–æ–≤–æ—Å—Ç—å, —Ç–µ–±–µ –µ—ë –Ω–∞–¥–æ –æ–∑–∞–≥–ª–∞–≤–∏—Ç—å (–æ–≥—Ä–∞–Ω–∏—á—å—Å—è 50 —Å–∏–º–≤–æ–ª–∞–º–∏) –∏ –ø–æ–º–µ—Å—Ç–∏ –µ–≥–æ —Å—Ç—Ä–æ–≥–æ –≤ –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É, –ø–æ—Ç–æ–º –Ω–∞–ø–∏—Å–∞—Ç—å —ç—Ç—É –∂–µ –Ω–æ–≤–æ—Å—Ç—å, –Ω–æ –∫—Ä–∞—Ç–∫–æ (–ø–æ—Å—Ç–∞—Ä–∞–π—Å—è –æ–≥—Ä–∞–Ω–∏—á–∏—Ç—å—Å—è 150 —Å–∏–º–≤–æ–ª–∞–º–∏). –ü–∏—à–∏ –±–µ–∑ —Å–ª–æ–≤ '–∑–∞–≥–æ–ª–æ–≤–æ–∫' –∏ '–Ω–∞–∑–≤–∞–Ω–∏–µ', –∏ '–∫—Ä–∞—Ç–∫–∏–π –ø–µ—Ä–µ—Å–∫–∞–∑'. –ó–∞–º–µ—á–∞–Ω–∏–µ: –µ—Å–ª–∏ –Ω–æ–≤–æ—Å—Ç—å –∏–Ω–æ—Å—Ç—Ä–∞–Ω–Ω–∞—è, —Ç–æ —Ç—ã –≤—Å—ë –Ω–µ –∑–∞–±—ã–≤–∞–µ—à—å –ø–µ—Ä–µ–≤–æ–¥–∏—Ç—å –Ω–∞ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫. –í–æ—Ç –Ω–æ–≤–æ—Å—Ç—å –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª–µ: {txt}"
             }
        ]
    }

    try:
        response = requests.post(url, headers=headers, json=data, timeout=(5, 60))
        response.raise_for_status()
        gpt_data = response.json()
        content = gpt_data['choices'][0]['message']['content']
        brief_text = content.split('</think>\n\n')[1]
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ GPT: {e}")
        return

    result = {
        "full_text": txt,
        "title": brief_text.split('\n')[0],
        "anons": '\n'.join(brief_text.split('\n')[1:]),
        "data": ""
    }

    with open(save_path, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=4)

    #with open(sent_path, 'w', encoding='utf-8') as f:
    #    json.dump(result, f, ensure_ascii=False, indent=4)

    logger.info(f"‚úÖ –ù–æ–≤–æ—Å—Ç—å –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {save_path}")




#from dotenv import load_dotenv
#import os
#import requests
#from pprint import pprint
#
#
#load_dotenv(os.path.join(os.path.dirname(__file__), '..', '..', '..', '..', '.env'))
#TSS = os.getenv("TSS")
#
#url = "https://api.intelligence.io.solutions/api/v1/chat/completions"
#headers = {
#    "Content-Type": "application/json",
#    "Authorization": TSS,
#}
#
#data = {
#    "model": "deepseek-ai/DeepSeek-R1",
#    "messages": [
#        {
#            "role": "system",
#            "content": "You are a very helpful assistant.",
#        },
#        {
#            "role": "user",
#            "content": input("–í–≤–µ–¥–∏—Ç–µ –ø—Ä–æ–º–ø—Ç:\n"),
#        }
#    ]
#}
#
#response = requests.post(url, headers=headers, json=data, timeout=(15, 120))
#response.raise_for_status()
#data = response.json()
#text = data['choices'][0]['message']['content']
#pprint(text.split('</think>\n\n')[1])
#
#processed_text = data['choices'][0]['message']['content']
#brief_text = processed_text.split('</think>\n\n')[1]
#choices = data.get("choices")